"""
Infinity OS â€” Vulnerability Scanner
Adapted from infinity-worker v5.4

OSV.dev API integration, multi-ecosystem CVE scanning, CVSS scoring,
automated remediation recommendations, SLA enforcement.
"""

import json
import hashlib
import re
import asyncio
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any, Tuple
from enum import Enum
from dataclasses import dataclass, field
from collections import defaultdict
import uuid

try:
    import httpx
    HTTPX_AVAILABLE = True
except ImportError:
    HTTPX_AVAILABLE = False


class Ecosystem(str, Enum):
    PYPI = "PyPI"
    NPM = "npm"
    GO = "Go"
    MAVEN = "Maven"
    RUBYGEMS = "RubyGems"
    CARGO = "crates.io"
    NUGET = "NuGet"
    DEBIAN = "Debian"
    ALPINE = "Alpine"


class VulnerabilitySeverity(str, Enum):
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    UNKNOWN = "unknown"


class RemediationStatus(str, Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    FIXED = "fixed"
    ACCEPTED_RISK = "accepted_risk"
    FALSE_POSITIVE = "false_positive"


# SLA days by severity (from cve-sla-check.js patterns)
SLA_DAYS: Dict[VulnerabilitySeverity, int] = {
    VulnerabilitySeverity.CRITICAL: 7,
    VulnerabilitySeverity.HIGH: 14,
    VulnerabilitySeverity.MEDIUM: 30,
    VulnerabilitySeverity.LOW: 90,
    VulnerabilitySeverity.UNKNOWN: 180,
}


@dataclass
class Vulnerability:
    id: str
    aliases: List[str]
    summary: str
    details: str
    severity: VulnerabilitySeverity
    cvss_score: Optional[float]
    cvss_vector: Optional[str]
    affected_package: str
    affected_ecosystem: str
    affected_versions: List[str]
    fixed_versions: List[str]
    references: List[Dict[str, str]]
    published: str
    modified: str
    remediation_status: RemediationStatus = RemediationStatus.PENDING
    sla_deadline: Optional[str] = None
    sla_breached: bool = False

    def __post_init__(self):
        if not self.sla_deadline:
            days = SLA_DAYS.get(self.severity, 180)
            try:
                pub = datetime.fromisoformat(self.published.replace("Z", "+00:00"))
                self.sla_deadline = (pub + timedelta(days=days)).isoformat()
                self.sla_breached = datetime.now(timezone.utc) > (pub + timedelta(days=days))
            except Exception:
                pass

    def to_dict(self) -> Dict:
        return {
            "id": self.id,
            "aliases": self.aliases,
            "summary": self.summary,
            "severity": self.severity.value,
            "cvss_score": self.cvss_score,
            "cvss_vector": self.cvss_vector,
            "affected_package": self.affected_package,
            "affected_ecosystem": self.affected_ecosystem,
            "fixed_versions": self.fixed_versions,
            "published": self.published,
            "remediation_status": self.remediation_status.value,
            "sla_deadline": self.sla_deadline,
            "sla_breached": self.sla_breached,
            "references": self.references[:3],
        }


@dataclass
class ScanResult:
    id: str
    scanned_at: str
    ecosystem: str
    package_count: int
    vulnerability_count: int
    critical_count: int
    high_count: int
    medium_count: int
    low_count: int
    sla_breached_count: int
    vulnerabilities: List[Vulnerability] = field(default_factory=list)
    scan_duration_ms: int = 0
    error: Optional[str] = None

    def to_dict(self) -> Dict:
        return {
            "id": self.id,
            "scanned_at": self.scanned_at,
            "ecosystem": self.ecosystem,
            "package_count": self.package_count,
            "vulnerability_count": self.vulnerability_count,
            "critical_count": self.critical_count,
            "high_count": self.high_count,
            "medium_count": self.medium_count,
            "low_count": self.low_count,
            "sla_breached_count": self.sla_breached_count,
            "scan_duration_ms": self.scan_duration_ms,
            "error": self.error,
            "vulnerabilities": [v.to_dict() for v in self.vulnerabilities],
        }


def _parse_severity(vuln_data: Dict) -> Tuple[VulnerabilitySeverity, Optional[float], Optional[str]]:
    """Parse severity from OSV vulnerability data."""
    severity = VulnerabilitySeverity.UNKNOWN
    cvss_score = None
    cvss_vector = None

    for sev in vuln_data.get("severity", []):
        sev_type = sev.get("type", "")
        score_str = sev.get("score", "")

        if "CVSS" in sev_type:
            cvss_vector = score_str
            # Parse CVSS base score from vector
            if "CVSS:3" in score_str:
                # Try to extract base score from AV:N/AC:L/... pattern
                try:
                    # Rough CVSS3 scoring from vector components
                    if "/AV:N/" in score_str and "/AC:L/" in score_str:
                        if "/PR:N/" in score_str:
                            cvss_score = 9.8 if "/C:H/" in score_str else 7.5
                        else:
                            cvss_score = 7.5
                    else:
                        cvss_score = 5.0
                except Exception:
                    cvss_score = 5.0

    # Map CVSS score to severity
    if cvss_score is not None:
        if cvss_score >= 9.0:
            severity = VulnerabilitySeverity.CRITICAL
        elif cvss_score >= 7.0:
            severity = VulnerabilitySeverity.HIGH
        elif cvss_score >= 4.0:
            severity = VulnerabilitySeverity.MEDIUM
        else:
            severity = VulnerabilitySeverity.LOW
    else:
        # Fallback: check database_specific severity
        db_specific = vuln_data.get("database_specific", {})
        sev_str = db_specific.get("severity", "").upper()
        if sev_str == "CRITICAL":
            severity = VulnerabilitySeverity.CRITICAL
            cvss_score = 9.5
        elif sev_str == "HIGH":
            severity = VulnerabilitySeverity.HIGH
            cvss_score = 7.5
        elif sev_str == "MODERATE" or sev_str == "MEDIUM":
            severity = VulnerabilitySeverity.MEDIUM
            cvss_score = 5.0
        elif sev_str == "LOW":
            severity = VulnerabilitySeverity.LOW
            cvss_score = 2.5

    return severity, cvss_score, cvss_vector


def _parse_osv_vulnerability(vuln_data: Dict, package_name: str, ecosystem: str) -> Vulnerability:
    """Parse an OSV API vulnerability response into our Vulnerability model."""
    severity, cvss_score, cvss_vector = _parse_severity(vuln_data)

    # Extract affected versions and fixed versions
    affected_versions = []
    fixed_versions = []

    for affected in vuln_data.get("affected", []):
        pkg = affected.get("package", {})
        if pkg.get("name", "").lower() == package_name.lower():
            for version_range in affected.get("ranges", []):
                for event in version_range.get("events", []):
                    if "introduced" in event:
                        affected_versions.append(f">={event['introduced']}")
                    if "fixed" in event:
                        fixed_versions.append(event["fixed"])
            # Also get explicit versions
            affected_versions.extend(affected.get("versions", [])[:5])

    return Vulnerability(
        id=vuln_data.get("id", "UNKNOWN"),
        aliases=vuln_data.get("aliases", []),
        summary=vuln_data.get("summary", "No summary available"),
        details=vuln_data.get("details", "")[:500],
        severity=severity,
        cvss_score=cvss_score,
        cvss_vector=cvss_vector,
        affected_package=package_name,
        affected_ecosystem=ecosystem,
        affected_versions=affected_versions[:10],
        fixed_versions=fixed_versions[:5],
        references=[{"url": r.get("url", "")} for r in vuln_data.get("references", [])[:5]],
        published=vuln_data.get("published", datetime.now(timezone.utc).isoformat()),
        modified=vuln_data.get("modified", datetime.now(timezone.utc).isoformat()),
    )


async def scan_package_osv(
    package_name: str,
    version: str,
    ecosystem: str,
) -> List[Vulnerability]:
    """Query OSV.dev API for vulnerabilities in a package."""
    if not HTTPX_AVAILABLE:
        return []

    url = "https://api.osv.dev/v1/query"
    payload = {
        "package": {
            "name": package_name,
            "ecosystem": ecosystem,
        },
        "version": version,
    }

    try:
        async with httpx.AsyncClient(timeout=10.0) as client:
            resp = await client.post(url, json=payload)
            if resp.status_code != 200:
                return []
            data = resp.json()
            vulns = []
            for vuln_data in data.get("vulns", []):
                vuln = _parse_osv_vulnerability(vuln_data, package_name, ecosystem)
                vulns.append(vuln)
            return vulns
    except Exception:
        return []


def parse_requirements_txt(content: str) -> List[Tuple[str, str]]:
    """Parse requirements.txt into (package, version) pairs."""
    packages = []
    for line in content.splitlines():
        line = line.strip()
        if not line or line.startswith("#") or line.startswith("-"):
            continue
        # Handle ==, >=, ~=, etc.
        match = re.match(r"^([a-zA-Z0-9_\-\.]+)\s*[=~><]+\s*([0-9][^\s;#]*)", line)
        if match:
            packages.append((match.group(1), match.group(2).strip()))
        else:
            # No version pinned
            match2 = re.match(r"^([a-zA-Z0-9_\-\.]+)", line)
            if match2:
                packages.append((match2.group(1), "latest"))
    return packages


def parse_package_json(content: str) -> List[Tuple[str, str]]:
    """Parse package.json into (package, version) pairs."""
    packages = []
    try:
        data = json.loads(content)
        for section in ["dependencies", "devDependencies"]:
            for name, version in data.get(section, {}).items():
                # Strip ^, ~, >=, etc.
                clean_version = re.sub(r"^[^0-9]*", "", version)
                packages.append((name, clean_version or version))
    except Exception:
        pass
    return packages


async def scan_dependencies(
    manifest_content: str,
    ecosystem: str,
    max_packages: int = 50,
) -> ScanResult:
    """
    Scan a dependency manifest for vulnerabilities.

    Args:
        manifest_content: Content of requirements.txt or package.json
        ecosystem: "PyPI" or "npm"
        max_packages: Maximum packages to scan (rate limiting)
    """
    start_time = datetime.now(timezone.utc)
    scan_id = str(uuid.uuid4())[:12]

    # Parse packages
    if ecosystem == Ecosystem.PYPI.value:
        packages = parse_requirements_txt(manifest_content)
    elif ecosystem == Ecosystem.NPM.value:
        packages = parse_package_json(manifest_content)
    else:
        return ScanResult(
            id=scan_id,
            scanned_at=start_time.isoformat(),
            ecosystem=ecosystem,
            package_count=0,
            vulnerability_count=0,
            critical_count=0,
            high_count=0,
            medium_count=0,
            low_count=0,
            sla_breached_count=0,
            error=f"Unsupported ecosystem: {ecosystem}",
        )

    packages = packages[:max_packages]
    all_vulns: List[Vulnerability] = []

    # Scan packages concurrently (batches of 10)
    batch_size = 10
    for i in range(0, len(packages), batch_size):
        batch = packages[i:i + batch_size]
        tasks = [scan_package_osv(name, version, ecosystem) for name, version in batch]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        for result in results:
            if isinstance(result, list):
                all_vulns.extend(result)

    # Deduplicate by CVE ID
    seen_ids = set()
    unique_vulns = []
    for v in all_vulns:
        if v.id not in seen_ids:
            seen_ids.add(v.id)
            unique_vulns.append(v)

    # Count by severity
    critical = sum(1 for v in unique_vulns if v.severity == VulnerabilitySeverity.CRITICAL)
    high = sum(1 for v in unique_vulns if v.severity == VulnerabilitySeverity.HIGH)
    medium = sum(1 for v in unique_vulns if v.severity == VulnerabilitySeverity.MEDIUM)
    low = sum(1 for v in unique_vulns if v.severity == VulnerabilitySeverity.LOW)
    sla_breached = sum(1 for v in unique_vulns if v.sla_breached)

    end_time = datetime.now(timezone.utc)
    duration_ms = int((end_time - start_time).total_seconds() * 1000)

    return ScanResult(
        id=scan_id,
        scanned_at=start_time.isoformat(),
        ecosystem=ecosystem,
        package_count=len(packages),
        vulnerability_count=len(unique_vulns),
        critical_count=critical,
        high_count=high,
        medium_count=medium,
        low_count=low,
        sla_breached_count=sla_breached,
        vulnerabilities=sorted(unique_vulns, key=lambda v: v.cvss_score or 0, reverse=True),
        scan_duration_ms=duration_ms,
    )


def get_remediation_priority(vulns: List[Vulnerability]) -> List[Dict[str, Any]]:
    """Generate prioritized remediation list."""
    priority_list = []
    for vuln in sorted(vulns, key=lambda v: (v.cvss_score or 0), reverse=True):
        if vuln.remediation_status in [RemediationStatus.FIXED, RemediationStatus.FALSE_POSITIVE]:
            continue
        priority_list.append({
            "id": vuln.id,
            "package": vuln.affected_package,
            "severity": vuln.severity.value,
            "cvss_score": vuln.cvss_score,
            "sla_breached": vuln.sla_breached,
            "sla_deadline": vuln.sla_deadline,
            "fix_available": len(vuln.fixed_versions) > 0,
            "fix_versions": vuln.fixed_versions,
            "action": f"Update {vuln.affected_package} to {vuln.fixed_versions[0]}" if vuln.fixed_versions else f"No fix available for {vuln.id}",
        })
    return priority_list